Полтора года назад, на одном из тренингов по публичным выступлениям нас попросили подготовить доклад минут на 5...

Вот кто любит делать домашнии задания?

Я точно нет, вот только не в тот раз. Я готовил то выступлдение всю ночь и не потому что боялся облажаться или
мне стыдно было прийти неподготовленным и даже не потому что хотел впечатлить преподавателя. Все потому что я выбрал
тему которая была мне реально интересна!

Только представте себе, у вас есть вечер на подготовку 5 минутного выступления, что вы будите делать?

Я потратил тогда всю ночь и подготовил выступление минут на 20, с кучей детально проработанных примеров, а все потому что
я готовил доклад на тему какие же е2е тесты мерзкие.

Вот только на утро, когда мы показывали что сделали, на мой шедевр не осталось времени, я готовился всю ночь,
но мне не дали выступить!
Любой бы наверное разозлился или обиделся в данной ситуации, но нет, я испытывал лишь чувства удовлетворенности
ведь я занимался любимым делом я НЕНАВИДЕЛ e2e тесты, боже мой я ненавижу их настолько сильно что даже готов не спать ночами
ТОЛЬКО ради того чтоб дольше их ненавидеть.

Возможно это звучит странно "Я ненавижу е2е тесты", Особенно если бы я один их ненавидел, но это не так.

Как оказалось я такой не один

J. B. Rainsberger - Он мой кумир, во первых он ненавидит даже не е2е тесты, он ненавидит INTEGRATED тесты,

Под этим термином он имеет ввиду все тесты результат выполнения которых(pass/fail) зависит от правильности реализации более
одного "нетривиального" поведения.

Причем ненавидеть и клеймить такие тесты мусором он начал в далеком 2008 //задолго до того как я узнал что бывает что-то помимо Unit тестов.

"Интегрированные тесты - это гадость - самовоспроизводящийся вирус, который угрожает заразить ваше тестирование,
ваш проект и команду бесконечной болью и страданиями." - Вот что он про них говорит.

Google тоже их ненавидет. Вернее он призывает отказаться от стратегии тестирования когда основное внимание уделяется
е2е тестам, которые должны эмулировать реальное поведение реальных пользователей. Если честно я был очень удивлен
услышав это от компании первый пункт философии которой --

"Сфокусируйтесь на пользователях и все остальное прийдет", тем не менее даже они уверяют что использование е2е тестов
скорее неизбежное зло чем хорошая идея, и призывают всех следить за их количеством, ведь если их у вас более 10% от общего количества тестов,
ВАМ будет больно.

Ненавидеть что-то легко, говорить что этот мерзость еще легче... первоначально я пошел по этому пути и устроил
разнос этим тестам, однако затем, немного поостыв я задался вопросами

Почему я их ненавижу?
Ведь я же не всегда их ненавидил?
Что привело к такой ситуации?

Для того чтоб ответить на них необходимо разобраться

Зачем мы пишем тесты?

// Проверить что наш продукт работает
// Проверить поведение до того как это сделают пользователи

Для того чтоб наши пользователи получили качественное ПО без багов!

// НО!

// Если продукт работает, то он работает -- неважно, что об этом говорит тест.
// Если продукт сломан, то он сломан -- и снова неважно, что об этом говорит тест.

Это цель тестирования, мы можем добиться этого и тестируя вручную, Так зачем мы пишем тесты?

Для того чтоб наши пользователи получили качественное ПО без багов, быстрее!

Т.е наша цель не найти багов больше всех, не написать кучу тестов.
Наша Цель найти, локализовать и исправить баги, а тесты это инструмент позволяющий это сделать быстрее!

Таким образом, чтобы оценить наши тесты, нашу стратегию тестирования, мы должны не просто посмотреть,
как это все находит ошибки.
Мы должны оценить, как наш подход позволяет разработчикам исправлять и даже предотвращать ошибки.

Итак что же из себя представляют е2е тесты?

В теории это лучшие тесты
Они фокусируются на пользователе, клиентах, на "реальных взаимодействиях".

Разработчики любят их, потому что они позволяют им не писать другие виды тестов.

Менеджеры любят их, потому что тесты, имитирующие реальные сценарии пользователя, могут помочь им легко определить,
как неудачный тест повлияет на пользователя.

Тестерам они нравятся, потому что они боятся пропустить баг или написать тест, который не не имеет никакого отношения к реальности;
написание e2e тестов помагают избежать обеих проблем и позволет продолжать работать с чувством выполненного долга.

Так же зачастую переход от ручного тестирования к автоматизированному тестированию происходит эволюционным путем
т.е. изначально мы тестируем продукт ручками, нарабатываем базу тест кейсов, формируем регриссионный сьют
и ЕДИНСТВЕННОЕ что в этом процессе нас неустраивает это скорость тестирования
и мы решаемся автоматизировать те кейсы что написали для ручного тестирования!

Так в чем же проблема? Почему писать только e2e тесты это плохо?

// что если нестабильность неплохо?
// the larger the tests, the more likely it will be flaky


е2е тесты - нестабильны, причем причин этой нестабильности много, и не все из них мы можем контролировать:
1) Concurrency
2) Cache
3) 3rd party systems
4) Test Ordering
5) Tests

К тому же их очень сложно дебажить, потому что непонятно как воспроизвести падение, но это не отменяет того факта что
мы должны разобраться в причине падения, ведь мы не знаем баг это или нет.

Однажды я вместе с коллегой потратили неделю чтоб разобраться в одном из таких падений, 2 человеко недели
нам понадобилось на то чтоб найти race-condition в одном из сервисов. Вот только в итоге эта проблема воспроизводилась
на rps больше 200, тогда как на продакшене этим сервисом практически никто не пользуется. Тем не менее мы молодцы, мы нашли баг.

Вот только сделали ли мы продукт лучше для конечного пользователя?

А как быть когда проблема в тестах или библиотеках которые используются только тестами?
Те же люди та же история, тест падает, причем падает регулярно, но только на машине у тимлида!
У меня и на CI он проходит.

А во всех компаниях разработчикам выдают более мощные машины?

Как оказалось у него на машине тесты выполнялись "слишком" быстро, да мы все еще говорим про е2е...
Тесты готовили себе моки в wiremock, это такой web-сервис, который может эмулировать любое поведение,
причем это поведение можно задавать прямо из тестов. Так вот сразу после того как тест подготовил мок он отправлял запрос
в сервис, а сервис шел за данными в wiremock, но он (wiremock) говорил что не знает что ему делать с этим запросом,
так как он еще не успел применить правила что тест ему отправил.

Вот как пофиксить такую проблему? Ведь сервис нам ответил что он создал заглушку!

sleep вначале теста, sleep вконце теста, sleep внутри теста, sleep в цикле...
С одной стороны я конечно понимаю что тестировать распределенные да еще и асинхронные системы сложно

Эта история всегда одинаковая для всех проектов, все начинают с нескольких сот милисекунд, вот только потом легко обнаружить
минутные слипы, однажды я даже нашел слип на 10 минут! Разумеется все они использовались исключительно чтоб стабилизировать тесты.

В одной из статей (https://testing.googleblog.com/2016/05/flaky-tests-at-google-and-how-we.html)
гугл признавался что даже у иних примерно 1.5% тестов нестабильны, как это не странно у нас тоже 1.5%.

1.5% это очень много, ведь у нас более 16 000 тестов, а это значит что 250 из них время от времени падают и все
эти падения необходимо разобрать, но да ладно о нас, в случае с google это более 63 000 падений (4.2 милиона тестов)

Как следствие регрессия на основе таких тестов становятся медленной

Что мы делаем если прогон тестов медленный? - Правильно паралелим его, и чем сильнее мы его паралелим тем больше тестов падает
и разумеется мы их фиксим с помощью слипов, вот такой вот порочный круг получается.

Но медленные они не только из-за слипов, так как мы тестируем реальную систему нас ожидают реальные взамиодействия внутри системы
Запись на диск, запись в базу данных, синхронизация данных, общение по сети.

Даже самый быстрый е2е тест выполняется несколько сот милисекунд, а если у вас тысячи таких тестов то регрессия занимает часы.

Разумеется никто не будет тестировать 5 минутный фикс несколько часов, вы начинаете копить изменения в командных или
релизных ветках.

Так зарождаются ночные прогоны, затем вы гоняете регрессию раз в неделю, раз в спринт, а потом вообще только перед
релизом, а чем больше изменений вы тестируете за один раз тем больше падений вы получите,
тем больше времени вы потратите на разбор этих падений... именно так умирает непрерывная интеграция!

Из-за огромного количества ложных падений рождается еще одна замечательная практика "заретраим" упавшие тесты,
пока они не позеленеют. Вот только во первых это маскирует плавающие проблемы, а во вторых удлиняет регрессию.
Причем иногда это доходит до смешного, мы например практикуем ретраи и зачастую тратим на них втрое больше времени
чем на основной прогон!

// Нужен вывод
// Они медленные не только по факту но и по духу!

И вы знаете, после попытки разбора падений е2е тестов, идея ретраить упавшие тесты до тех пор пока они не позеленеют
не так уж и плоха. Ведь причиной падения может быть все что угодно: Окружение, конфигурация, сеть, тесты, код.
И даже просто найти место, и причину падения не так то и просто учитывая что вам известно что что-то пошло не так!

Конечно всегда можно просто завести баг и повесить его на разработчика, вот только это никак не поможет понять что и
где сломалось!


Так как мы проверяем всю систему целиком, порой очень сложно подготовить данные именно под тот сценарий что вы хотите написать.
А если в системе сотни сервисов и десятки баз данных, то зачастую это еще и невозможно.

Каждый раз когда передо мной встает вопрос: Построить целую вселенную для сценария который неплохо было бы протестировать
или забыть о нем? Я выбираю забыть! Ведь эту вселенную нужно не только построить, но и поддерживать потом и если
впервые столкнувшись с подобной задачей можно воспринимать ее как вызов (challenge), как что-то чем можно гордиться,
то со временем об этом хочется поскорее забыть и не вспоминать, потому как 90% времени вы потратите ожидая ответов на свои
вопросы или пока кто-то реализует нужный вам интерфейс для подготовки этих данных.

Бесконечные ожидания и согласования не нравятся никому, как итог рано или поздно вы забьете на все экзотические случаи.

Да и со стандартными кейсами тоже не все так просто, начиная готовить данные в тестах вы быстро поймете что подготовка
занимает намного больше времени чем сами тесты, и я сейчас говорю не только про запуск и выполнение но еще и про написание.

Как итог почти все выносят этап подготовки данных из тестов в отдельный сервис, в дженкинс джобу, да впринципе куда угодоно.

И мы уже не понимаем с какими данными работает наш тест, мы не понимаем какие данные нам нужно брать для теста который мы пишем,
мы потеряли читаемость и простоту тестов! они теперь пестрят магическими строками и числами!

// Беседа о тестовых данных https://sqadays.com/ru/talk/3488

Все так вы не ослышались, они действительно масштабируются комбинаторно!

А это значит что вам потребуется просто астрономическое кеоличество тестов чтоб полностью протестировать вашу систему:
Например вы разрабатываете небольшую сферическую микросервисную систему в вакууме состоящую из 12 микросервисов
и в половине этих сервисов есть хоть какая то условная логика. Полный набор е2е тестов для этой системы
будет содержать в себе более 2.5^12 59 605 тестов!

Сколько потребуется времени чтоб писать 60 000 тестов? Если для каждого теста требуется 30 минут,
это включает в себя время на подумать, время,
затрачиваемое на тестирование, чтобы оно проходило в первый раз, и время на поддержку тестового окружения т. д.
- то есть вам потребуется 3 750 человеко-дней или 750 человеко недель ну или 2 человеко-года.

ВАМ понадобятся два тестировщиков которые будут писать эти тесты
восемь часов в день в течении года, и молитесь, чтоб они ни разу не допустили ошибку в тестах,
потому что у вас нет времени переписывать эти тесты.

Вот только в реальной жизни все подругому У нас 15 тестировщиков, в семь раз больше, и мы пишем около 50 тестов в неделю,
а это всего-то 2 500 тестов в год! Не 60 000!

4% от числа, необходимого для полного тестирования системы.
Даже если вдруг вы написали самые важные 4%, признав почти бесконечное дублирование в полном комплекте тестов,
вы бы покрыли где-то между 10% и 80% вашего кода, и вы не знаете, приближаетесь ли вы к 10% или 80%,
пока ваши клиенты не начнут использовать ваш первый релиз. Круто? А?

Таким образом, вы пишете 2 500 тестов. Возможно, вы даже написали 5 000.

Когда клиент обнаружит ошибку, что вы сделаете? Правильно, напишите еще немного e2e тестов. Чем больше e2e тесты вы пишете,
тем больше ощущается ложное чувство безопасности. Помните, что вы просто увеличили тестовое покрытие с 4% до 4%
с помощью этих десяти e2e тестов.
Это ложное чувство безопасности помогает вам чувствовать себя хорошо выпуская еще более неработающий код для ваших клиентов,
а это значит, что они находят больше дефектов, которые вы покрываете еще большим кроличеством e2e тестов.
Со временем ваше покрытие кода уменьшается, потому что сложность кодовой базы растет быстрее,
чем способность писать достаточное количество e2e тестов для ее покрытия....

Вы не cможете выиграть эту игру. Мы не смогли! // перефразировать

Зато все эти свойства е2е тестов:
1) Нестабильные
2) Медленные
3) Неинформативные
4) Требуют подготовки данных
5) Масштабируются комбинаторно, прям как вирус

Дают возможность тестировщикам поиграть в программистов и написать свой собственный тестовый фреймворк

Ну или генератор тестовых данных, или новый фреймворк для тестовых отчетов. И возможно в этом бы неыло проблемы,
вот только этот очередной велосипед оказывается ничем не лучше чем старый и конечно этот монстр, рожденный в недрах
компании людьми которые ниразу не написали и строчки продакшн кода, никогда не увидит свет open source'а.

А посему так и останется жить в этой компании и пугать новоприбывших. Вспомните сколько нужно времени чтоб новичок
вник в суть происходящего, чтоб он понял как у вас все устроенно, как же ему выполнять его работу!

// rc rest assured, rc test ng, ci dashboard,

Работодатели тоже кстати активно ведутся на эту чушь:
"Наши тесты печалька, регрессия занимает больше времени чем если бы мы тестировали руками,
а все потому что наш тестовый фреймворк несмог". И вот на свет рождается новый тестовый фреймворк
"Ну сейчас то точно получится v3", от создателей "Нам нужен тестовый фреймворк" и "Нам нужно переписать тестовый фреймоврк"

Нет не получится - ни один тестовый фреймворк не сделает е2е тесты:
1) Стабильными
2) Быстрыми, быстрее юнит тестов
3) Информативными
4) Он не избавит вас от подготовки данных
5) Он не сможет сократить количество ваших тестов

Так за что же я их ненавижу, спросите вы?

Зато то что они:
1) Нестабильные
2) Медленные
3) Неинформативные
4) Требуют подготовки данных
5) Масштабируются комбинаторно

??? НЕТ, НЕТ, НЕТ и еще раз НЕТ! они такие какие есть!
Я ненавижу их за то что они вселяеют тестировщикам ложное чувство безопасности, ведь "Мы тестируем реальные взаимодействия!"
Я ненавижу их за то что из-за них тестировщики перестали смотреть в код!
Я ненавижу их за то что из-за них тестировщики считают что Юнит тесты это про ТДД и для разработчиков!
Я ненавижу их за то что из-за них тестировщики перестали думать о том как же можно эффективно протестировать фичу!

У меня полтора года ушло на осознание простого факта что странно ненавидеть микроскоп за то что им забивают гвозди!

Дорогие тестировщики, пожалуйста вспомните про другие виды тестирования, да да все те что вы перечисляете на собеседовании

Юнит тестирование
Компонентное тестирование
Контрактное тестирование
Интеграционное тестирование
Тестирование конфигурации

Начните уже наконец их использовать на своей текущей работе а не только для поиска новой!

Начните считаете профит от тестов.

А если вы двруг нашли медленный или нестабильный или сложный е2е тест, помните его всегда можно заменить комбинацией
тестов другого типа! Да его можно даже переписать используя только юнит тесты!

Любой "реальный" сценарий это всего лишь цепочка вызова функций с заранее известными параметрами!

Только комбинируя разные техники написания тестов, вы сможете писать меньше тестов,
они будут быстрее, вы будете быстрее и точнее получать фидбек о качестве вашего по
Тесты наконец то перестанут висеть мертвым грузом!

Откажитесь от стратегии тестирования только e2e тестами!
Тестировать только e2e тестами это мерзко!
